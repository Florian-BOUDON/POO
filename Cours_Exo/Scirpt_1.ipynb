{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librairie\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataManager:\n",
    "\n",
    "    # Initialisation : lecture des données\n",
    "    def __init__(self, filepath, **csv_options):\n",
    "        self.df = pd.read_csv(filepath, **csv_options)\n",
    "        self.feature_names = []\n",
    "\n",
    "    # Module permettant de centrer-réduire les données, imputation par mediane, onehotencoder\n",
    "    def preprocess(self):\n",
    "        num_features = self.df.select_dtypes(include=['int64','float64']).columns\n",
    "        cat_features = self.df.select_dtypes(include=['object']).columns\n",
    "\n",
    "        num_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ])\n",
    "\n",
    "        cat_transformer = Pipeline( steps=[\n",
    "            ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
    "            ('scaler', StandardScaler(with_mean=False))\n",
    "        ])\n",
    "\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', num_transformer, num_features),\n",
    "                ('cat', cat_transformer, cat_features) ])\n",
    "        \n",
    "        self.df = pd.DataFrame(preprocessor.fit_transform(self.df))\n",
    "\n",
    "        self.update_feature_names(preprocessor, num_features, cat_features)\n",
    "\n",
    "    # Module permettant de reccupérer les valeurs des variables categorielles\n",
    "    def update_feature_names(self, preprocessor, num_features, cat_features):\n",
    "        categ_features = preprocessor.named_transformers_['cat']['onehote'].get_feature_names_out(cat_features)\n",
    "        self.feature_names = num_features.to_list() + categ_features.tolist()\n",
    "\n",
    "    # Module permettant de reccupérer le df après le traitement\n",
    "    def get_data(self):\n",
    "        return self.df\n",
    "    \n",
    "    # Module permettant d'avoir accès au caractéristique des variables catégorielles\n",
    "    def get_feature_names(self):\n",
    "        return self.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple d'utilisation\n",
    "\n",
    "file_path = \"data.csv\"\n",
    "data_manager = DataManager(file_path, sep=',', header=0)\n",
    "data_manager.preprocess()\n",
    "data = data_manager.get_data()\n",
    "feature_names = data_manager.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "class ACP:\n",
    "\n",
    "    def __init__(self, n_components=4):\n",
    "        self.n_components = n_components\n",
    "        self.pca = PCA(n_components = n_components)\n",
    "        self.components_ = None\n",
    "        self.explained_variance_ = None\n",
    "\n",
    "    def fit(self, data):\n",
    "        self.pca.fit(data)\n",
    "        self.components_ = self.pca.components_\n",
    "        self.explained_variance_ = self.pca.explained_variance_\n",
    "\n",
    "    def get_eigenvalues(self):\n",
    "        return self.explained_variance_\n",
    "    \n",
    "    def get_contributions(self):\n",
    "        contributions= np.square(self.components_)*100\n",
    "        df_contributions = pd.DataFrame(contributions.T, columns=[f\"PC{i+1}\" for i in range(self.n_components)])\n",
    "        return df_contributions\n",
    "    \n",
    "    def get_circle_of_correlations(self):\n",
    "        circle_values = self.components_.T\n",
    "        df_circle = pd.DataFrame(circle_values, columns=[f\"PC{i+1}\" for i in range(self.n_components)] )\n",
    "        return df_circle\n",
    "    \n",
    "    def select_variables_for_circle(self, variables, df_circle):\n",
    "        return df_circle[df_circle.index.isin(variables)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
